<<set-parent, echo=FALSE, cache=FALSE>>=
knitr::set_parent('main-CA-403_notas.Rtex')
@

\chapter{Jacknife y Bootstrap}


Suponga que se quiere estimar un intervalo de confianza para la media \(\mu\) desconocida de un conjunto de datos \(X_{1},\ldots, X_{n}\) que tiene distribución  \(\mathcal{N}\left(\mu ,\sigma^{2}\right)\). 

Primero se  conoce que 

\begin{equation*}
\sqrt{n}\left( \hat{\theta} - \theta \right) 
\xrightarrow{\mathcal{L}} \mathcal{N}\left(0,\sigma^{2}\right),
\end{equation*}

y esto nos permite escribir el intervalo de confianza como 

\begin{equation*}
\left[ \hat{\mu} - \hat{\sigma}z_{1-\frac{\alpha}{2}} , 
\hat{\theta} + \hat{\sigma}z_{1-\frac{\alpha}{2}}\right] 
\end{equation*}

donde \(z_{1-\frac{\alpha}{2}}\) es el cuantil \(1-\frac{\alpha}{2}\) de una normal estándar.

La expresión anterior es posible ya que el supuesto es que la
distribución de \(\hat{\theta}\) es normal.

\begin{pregunta}{}{}
	¿Qué pasaría si este supuesto es falso o al menos no conocemos la distribución de \(\hat{\theta}\)?
	
	¿Cómo podemos encontrar ese intervalo de confianza?
\end{pregunta}

\begin{cuidado}{}{}
	Para una muestra fija, el estimador anterior  \(\hat{\mu}\)  solamente un valor.  No se conoce la distribución de \(\hat{\mu}\). Lo único que se puede estimar son valores puntuales como la media, varianza, mediana, etc, pero no sabemos nada de su distribución.
\end{cuidado}


\subsection{Caso concreto}

Suponga que tenemos la siguiente tabla de datos, que representa una muestra de tiempos y distancias de viajes en Atlanta. 

Cargamos la base de la siguiente forma:

<<CommuteAtlanta, error=TRUE>>=
CommuteAtlanta <- read.csv2("data/CommuteAtlanta.csv")
knitr::kable(head(CommuteAtlanta))
@

Para este ejemplo tomaremos la variable \texttt{Time} que la llamaremos \texttt{x} para ser más breves. En este caso note que 

<<assign-Time-to-x>>=
x <- CommuteAtlanta$Time
@

<<meanTime>>=
mean(x)
@ 

y su varianza es 

<<varTime>>=
var(x)
@ 


A partir de estos dos valores, ¿Cuál sería un intervalo de confianza para la media? 

Note que esta pregunta es difícil ya que no tenemos ningún tipo de información adicional. 

Las dos técnicas que veremos a continuación nos permitirán extraer  \emph{información adicional} de la muestra. 

\begin{nota}{}{}
	Para efectos de este capítulo, llamaremos \(T_{n}=T\left( X_{1},\ldots,X_{n}\right)\) al estadístico formado por la muestra de los \(X_{i}\)'s.
\end{nota}

\newpage

\section{Jacknife}

Esta técnica fue propuesta por \cite{Quenouille1949} y consiste en la siguiente observación. 

Se puede probar que muchos de los estimadores tiene la propiedad que 

\begin{equation}
\operatorname{Sesgo}\left(T_{n}\right)=\frac{a}{n}+\frac{b}{n^{2}}+O\left(\frac{1}{n^{3}}\right)
\end{equation}

para algún $a$ and $b$. 

Por ejemplo $\sigma^{2}=\mathrm{Var}\left(X_{i}\right)$ y sea $\widehat{\sigma}_{n}^{2}=n^{-1} \sum_{i=1}^{n}\left(X_{i}-\right.$ $\bar{X})^{2}$. Entonces, 

\begin{equation*}
\mathbb{E}\left(\widehat{\sigma}_{n}^{2}\right)= \frac{n-1}{n}\sigma^{2}
\end{equation*}

por lo tanto 

\begin{equation*}
\mathrm{Sesgo} = -\frac{\sigma^{2}}{n}
\end{equation*}

Por lo tanto en este caso $a=-\sigma^{2}$ y $b=0$.



Defina \(T_{(-i)}\) como el estimador \(T_{n}\) pero eliminando el \(i\)-ésimo término. 

Es claro que en este contexto, se tiene que 

\begin{equation}
\operatorname{Sesgo}\left(T_{(-i)}\right)=\frac{a}{n-1}+\frac{b}{(n-1)^{2}}+O\left(\frac{1}{(n-1)^{3}}\right)
\end{equation}

\begin{laboratorio}{}{}
Una forma fácil de construir los \(T_{(-i)}\) es primero replicando la matriz de datos multiple veces usando el producto de kronecker

<<jackdf>>=
n <- length(x)
jackdf <- kronecker(matrix(1, 1, n), x)

jackdf[1:10, 1:10]
@

Y luego se elimina la diagonal

<<jackdfNA>>=
diag(jackdf) <- NA

jackdf[1:10, 1:10]
@

Cada columna contiene toda la muestra excepto el \(i\)-ésimo elemento. Solo basta estimar la media

<<jack-T-i>>=
T_i <- colMeans(jackdf, na.rm = TRUE)

T_i[1:10]
@

\end{laboratorio}

Definamos el sesgo \emph{jackife} como 

\begin{equation*}
b_{jack} = (n-1) (\overline{T}_{n} - T_{n})
\end{equation*}
donde 
\begin{equation*}
\overline{T}_{n} = \frac{1}{n} \sum_{i=1}^{n} T_{(-i)}
\end{equation*}


Observe que este valor tiene la siguiente propiedad 

\begin{align*}
\mathbb{E}\left(b_{\text {jack }}\right) 
&=(n-1)\left(\mathbb{E}\left(\operatorname{Sesgo}\left(\overline{T}_{n}\right)\right)
-\mathbb{E}\left(\operatorname{Sesgo}\left(T_{n}\right)\right)\right) \\
&=(n-1)\left[\left(\frac{1}{n-1}
-\frac{1}{n}\right) 
a+\left(\frac{1}{(n-1)^{2}}
-\frac{1}{n^{2}}\right) b+O\left(\frac{1}{n^{3}}\right)\right] \\
&=\frac{a}{n}
+\frac{(2 n-1) b}{n^{2}(n-1)}
+O\left(\frac{1}{n^{2}}\right) \\
&=\operatorname{Sesgo}\left(T_{n}\right)
+O\left(\frac{1}{n^{2}}\right)
\end{align*}

\begin{laboratorio}{}{}
	
\end{laboratorio}